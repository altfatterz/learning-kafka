bootstrap.servers=localhost:29092

# Best practice for Kafka producer to prevent data loss
# Used to determine when a write request is successful.
# Starting from Kafka 3.0, the default for 'acks' is 'all' instead of '1'
acks=all

key.serializer=org.apache.kafka.common.serialization.StringSerializer
value.serializer=org.apache.kafka.common.serialization.StringSerializer

# default 16384
# Max number of bytes for a batch of messages sent to a partition
batch.size=2000
# Time a batch will wait to accumulate before sending. Default is 0
linger.ms=5000

# String to identify this producer uniquely; used in monitoring and logs
# Default producer-1
client.id=producer-1

# How data should be compressed. Compression is performed on batches of records. Default is none
# Possible values: none, snappy, gzip, lz4, zstd.
# Check without compression and with compression and see in the logs the `MemoryRecord` size
# Compression is end-to-end: compressed on the Producer, stored in compressed format on the Broker, decompressed on the Consumer
# You can have one producer compressing and another producer not compressing messages, both writing to same topic.
# compression.type=snappy

topic=test-topic